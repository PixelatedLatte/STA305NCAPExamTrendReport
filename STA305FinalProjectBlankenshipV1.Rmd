---
title: "Relationship between Test Scores and Population: Report"
author: "Jacob Blankenship"
date: "12/4/2025"
output: html_document
---

General idea: First include a graph on distribution of good AP score's and maybe compare to to distribution of test takers, then make a graph comparing good AP score vs County population/Density to see if rural counties produce worse AP scorers. Finally create a linear model so see if county population/Density is a good predictor for AP exams.

### Report Section 1 - Introduction:

In general terms I wanted to explore how academic performance differs across communities in North Carolina. The state provides clean publicly available data on AP standardized test scores and population estimates, which allow for geographic comparison of educational outcomes. Because AP exams are an optional indicator of advanced coursework, counties with more resources or larger student populations may perform differently.

The specific variables I was looking for were:
1. County Names
2. Number of AP Exams taken by County
3. Percent of passed AP Exams by County (3/5 or higher)
4. Longitude and Latitude coordinates of counties to create map plots

My Research question is:
"Does population size of a North Carolina county predict AP exam success rates?”

Links to source are given below.

https://www.osbm.nc.gov/facts-figures/population-demographics/state-demographer/county-population-estimates/certified-county-population-estimates

https://www.dpi.nc.gov/2025-ap-test-results


#### Initial Imports
```{r DataImports+InitialLoads, warning=FALSE, echo=TRUE, message = FALSE}
# initial packages install
packages <- c("ggplot2", "dplyr", "readxl", "maps", "scales", "sf", "ggrepel", "tidymodels")
missing <- packages[!(packages %in% installed.packages()[,"Package"])]
if (length(missing) > 0) install.packages(missing)

# load packages + add NC map data (for polygons)
invisible(lapply(packages, library, character.only = TRUE))
#https://www.dpi.nc.gov/2025-ap-test-results
NCScoreData <- read_excel("Import2025NC.AP.RESULTS.xlsx")
NCPopData <- read_excel("NCPopulationCensusData.xlsx")
NCMapData <- map_data( "county", 
                   region = "north carolina" )

```

### Report Section 2 - Data Analysis:

I wanted my explanatory variable to be the population and my predictor variable to be the AP exam proficient percent.

Before any modeling or visualization, the datasets required extensive cleaning to ensure valid comparisons between maps and score data. This included removing duplicate regions, converting character fields to numeric values, standardizing county names, and computing geometric centroids for map labeling. It should also be noted that I edited the .xslx files that I directly downloaded as some small formatting changes made the file much more workable in r.

#### Data Cleaning
```{r DataCleaning, warning=FALSE, message = FALSE}
NCScoreData <- NCScoreData %>% rename_at(vars(3), ~ "County") %>% filter(is.na(`School System & School`)) %>% filter(grepl("County", County)) %>%
  select(
    `2025`,
    County,
    `# of Exams Taken5`,
    `# of Exams with Scores of 3 or Higher6`,
    `% of Exams with Scores of 3 or Higher7`
  ) %>% mutate(
    Exams = case_when(`# of Exams Taken5` == "*" ~ "", TRUE ~ `# of Exams Taken5`),
    GoodScore = case_when(
      `# of Exams with Scores of 3 or Higher6` == "*" ~ "",
      TRUE ~ `# of Exams with Scores of 3 or Higher6`
    ),
    Percentage = case_when(
      `% of Exams with Scores of 3 or Higher7` == "*" ~ "",
      TRUE ~ `% of Exams with Scores of 3 or Higher7`
    )
  ) %>% rename_at(vars(1), ~ "ID") %>% select(ID,County,Exams,GoodScore,Percentage) %>% filter(ID != "73B")
# ^ SPECIFICALLY TAKING OUT A DUPLICATE POINT. EMAILED GOV TO CLARIFY IN MEANTIME

# Setting chars to lower, and taking out County from fields to 
# make values match with map data
NCScoreData$County <- gsub(" County", "", NCScoreData$County) 
NCScoreData$County <- tolower(NCScoreData$County)

# converting nums to num types (for graph)
NCScoreData$Percentage <- as.numeric(as.character(NCScoreData$Percentage))
NCScoreData$Exams <- as.numeric(as.character(NCScoreData$Exams))
NCScoreData$GoodScore <- as.numeric(as.character(NCScoreData$GoodScore))


#setequal(unique(NCMapData$subregion), unique(NCScoreDataClean$County))

# Left join to get points
NCScoreDataClean <- left_join(NCScoreData, NCMapData, by = c('County' = 'subregion'))

# Manually put in centroid formula for accurate centered points (package wasn't working)
CountyCenters <- NCMapData %>%
  group_by(subregion, group) %>%
  summarise(
    A = 0.5 * sum(
      long * lead(lat, default = first(lat)) - lead(long, default = first(long)) * lat
    ),
    long_c = sum((long + lead(
      long, default = first(long)
    )) *
      (
        long * lead(lat, default = first(lat)) - lead(long, default = first(long)) * lat
      )) / (6 * A),
    lat_c  = sum((lat + lead(lat, default = first(
      lat
    ))) *
      (
        long * lead(lat, default = first(lat)) - lead(long, default = first(long)) * lat
      )) / (6 * A)
  ) %>%
  group_by(subregion) %>%
  summarise(long = mean(long_c), lat = mean(lat_c)) %>%
  ungroup()

# Adding in extra values to make points more informative (add filtering capability)
CountyCenters <- CountyCenters %>%
  left_join(NCScoreData %>% 
              select(County, Percentage, Exams, GoodScore),
            by = c("subregion" = "County"))
# Reconvert to have first letter uppercase to make it look nice
CountyCenters$subregion <- paste0(
  toupper(substr(CountyCenters$subregion, 1, 1)),
  substr(CountyCenters$subregion, 2, nchar(CountyCenters$subregion))
)
NCPopData <- NCPopData %>% filter(County != "State of North Carolina")
CountyCenters <- CountyCenters %>% left_join(NCPopData %>% select(County,Population),
                                             by = c("subregion" = "County"))
CountyCenters <- CountyCenters %>%
  mutate(
    Highlight = case_when(
      min_rank(Percentage) <= 5 ~ "Bottom 5",                     # 5 lowest percentages
      min_rank(desc(Percentage)) <= 5 ~ "Top 5",                 # 5 highest percentages
      TRUE ~ "Other"
    )
  )
```

Now that my data is clean I can do general summary statistics by County.

#### Summary Statistics
````{r SummaryStats}
CountyCenters %>%
  summarise(
    count = n(),
    # Population
    mean_population = mean(Population, na.rm = TRUE),
    sd_population = sd(Population, na.rm = TRUE),
    min_population = min(Population, na.rm = TRUE),
    max_population = max(Population, na.rm = TRUE),
    # Percentage of good AP scores
    mean_percentage = mean(Percentage, na.rm = TRUE),
    sd_percentage = sd(Percentage, na.rm = TRUE),
    min_percentage = min(Percentage, na.rm = TRUE),
    max_percentage = max(Percentage, na.rm = TRUE),
    # Number of exams
    mean_exams = mean(Exams, na.rm = TRUE),
    sd_exams = sd(Exams, na.rm = TRUE),
    min_exams = min(Exams, na.rm = TRUE),
    max_exams = max(Exams, na.rm = TRUE)
  )
````

I needed a better way of showing the viewer what this data should look like. To combat this (especially to people that are unfamiliar with the AP exam or North Carolina), I wanted to create a weighted mapped plot of exam scores. This way people can get a representation of population density and overall performance in exams across the county before my model is created.

#### Visualization #1
```{r DataVisual1, fig.width=8, fig.height=5, warning = FALSE}
# Labs + Theme
JacobLabs1 <- labs(title = "North Carolina's Percent of Passed AP Exams by County",
                   subtitle = "2025 AP Exam Results",
                   caption = "NA value are gray, Data comes from www.dpi.nc.gov")
JacobTheme1 <- theme_bw() + theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + theme(
  axis.text.x = element_blank(),
  axis.ticks.x = element_blank(),
  axis.text.y = element_blank(),
  axis.ticks.y = element_blank(),
  panel.grid.major = element_blank(),
  panel.grid.minor = element_blank(),
  text = element_text(face = "bold")
)

# Making initial map plot
NCScoreDataClean %>%
  ggplot(aes(
    x = long,
    y = lat,
    group = group,
    fill = Percentage
  )) +
  geom_polygon(color = "#999999") +
  scale_fill_gradient2(
    low = "#E81B23",
    mid = "white",
    high = "#00AEF3",
    midpoint = 50,
    na.value = "lightgray"
  ) + geom_point(
    data = CountyCenters,
    aes(x = long, y = lat, size = Population, color = Highlight),
    inherit.aes = FALSE
  ) +
  scale_color_manual(values = c("Top 5" = "black", "Bottom 5" = "black", "Other" = "#999999")) + guides(color = "none") +
  geom_text_repel(
    data = CountyCenters %>% filter(Highlight != "Other"),
    aes(label = subregion, x = long, y = lat),
    color = "black",
    size = 4,
    inherit.aes = FALSE,
    fontface = "bold",
    max.overlaps = Inf,
    box.padding = 0.5,
    point.padding = 0.1
  ) +
  # Points for all counties, color by highlight
  JacobLabs1 + JacobTheme1
```

This visualization highlights both the spatial variation in AP performance and the disparity in the number of test takers among counties, which helps motivate whether population should reasonably act as a predictor.

I also wanted to understand whether AP performance changes with community size, I used population as an explanatory variable and AP score pass rate as the response variable. I then fit linear, log-linear, and polynomial models to compare whether the relationship is linear or non-linear, and if the correlational coefficient was better for said mappings.


#### Visualization #1
```{r DataVisual2, warning=FALSE, message = FALSE}
   JacobLabs2 <- labs(title = "North Carolina's Proficent AP Test Scores vs Population vs Exams taken", caption = "2025 AP Exam Results, 2024 Census Data", y = "Percentage of passed AP Exams", x= "Population of County")
    JacobTheme2 <- theme_bw()
    CountyCenters %>%
  filter(!is.na(Population), !is.na(Percentage), !is.na(Exams)) %>%
  ggplot(aes(x = Population, y = Percentage, size = Exams)) +

  # Linear
  geom_smooth(method = "lm", se = FALSE, aes(color = "Linear"), linetype = "solid") +

  # Log-linear
  geom_smooth(method = "lm", formula = y ~ log(x), se = FALSE, aes(color = "Log(Pop)"), linetype = "solid") +

  # Quadratic
  geom_smooth(method = "lm", formula = y ~ x + I(x^2), se = FALSE, aes(color = "Quadratic"), linetype = "solid") +

  # Points
  geom_point(shape = 21, color = "darkgray", fill = "#5d68fc", stroke = 0.8) +

  # Top/bottom 5 labels
  geom_text_repel(
    data = CountyCenters %>%
      filter(!is.na(Percentage)) %>%
      arrange(Percentage) %>%
      slice(c(1:5, (n() - 4):n())),
    aes(label = subregion, x = Population, y = Percentage),
    color = "black",
    size = 3,
    inherit.aes = FALSE,
    fontface = "bold",
    max.overlaps = Inf,
    box.padding = 0.3,
    point.padding = 0.1
  ) +

  # Labels & theme
  JacobLabs2 + JacobTheme2 +
  scale_color_manual(name = "Model Type", values = c("Linear" = "red", "Log(Pop)" = "purple", "Quadratic" = "darkgreen")) + guides(
    size = guide_legend(
      override.aes = list(shape = 21, fill = "#5d68fc", color = "white", stroke = 0.8)
    )
  )



model_data <- CountyCenters %>%
  filter(!is.na(Population), !is.na(Percentage), Population > 0, Percentage > 0)

# Linear model
LinReg <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Percentage ~ Population, data = model_data)

# ️Log-linear: log(Population)
LogPopReg <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Percentage ~ log(Population), data = model_data)

# Polynomial
PolyReg <- linear_reg() %>%
  set_engine("lm") %>%
  fit(Percentage ~ Population + I(Population^2), data = model_data)

# Show coefficients
LinReg %>% tidy()
LogPopReg %>% tidy()
PolyReg %>% tidy()

# Show R-squared
glance(LinReg)$r.squared
glance(LogPopReg)$r.squared
glance(PolyReg)$r.squared
```
The map above shows that while high population counties like Wake and Mecklenburg do have above average pass rates, much smaller counties such as Polk or Carteret outperform them significantly, suggesting that population may not drive quality.

**Linear:**

County Exam Percentage = 60.99 + 0.0000155 x Population

R^2 = 0.03097748

**Logarithmic:**

County Exam Percentage = 37.05 + 2.32 x log(Population)

R^2 = 0.0183111

**Exponential/Polynomial:**

County Exam Percentage = 59.33 + (3.67x10^-5) x Population - (1.94x10^-11) x Population^2

R^2 = 0.03861632

Overall there is little to no linear,logarithmic,or polynomial(n^2) correlational relationship between Population of County and County AP Exam Percentage. The best model, a polynomial regression, only slightly improved fit, suggesting no meaningful predictive relationship with our current dataset.

Critiques:

1. Several counties reported insufficient AP testing data, leading to missing values for roughly 20% of regions. This may bias estimates toward larger school systems with more complete reporting.

2. Census estimates are from 2024, while AP results are from 2025; demographic changes within a year may reduce precision in population-based modeling.

3. Things such as population density within counties is not taken into account. So if a very large school is shown in a very population low county, it would still flag as a small data point A more accurate marker to test may be average or median population in highschool's of each county.




